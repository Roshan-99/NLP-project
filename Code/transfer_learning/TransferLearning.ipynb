{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20851,"status":"ok","timestamp":1669521174087,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"},"user_tz":480},"id":"7VXFSmhQpkUS","outputId":"a799f364-7a77-4347-e553-643b7956ef8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1669521174089,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"},"user_tz":480},"id":"flzoDg4AlzML","colab":{"base_uri":"https://localhost:8080/"},"outputId":"87e01769-8879-45df-ec7c-8ffb96a5eaf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/Code\n"]}],"source":["cd /content/drive/My Drive/Colab Notebooks/Code/"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Q9SpwpLg3h6L","executionInfo":{"status":"ok","timestamp":1669521185625,"user_tz":480,"elapsed":275,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}}},"outputs":[],"source":["import os\n","import csv\n","import pandas as pd\n","class TransferLearning(object):\n","\n","    categories = ['goal','description','scope','requirements','architecture','users','summary']\n","    path = os.getcwd()+'/../Data'\n","\n","    def __init__(self):\n","        print('Transfer Learning Results...')"]},{"cell_type":"markdown","metadata":{"id":"IZ6SNYq_tVVC"},"source":["# Classify text with BERT\n","\n","This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews.\n","In addition to training a model, you will learn how to preprocess text into an appropriate format.\n","\n","In this notebook, you will:\n","\n","- Load the IMDB dataset\n","- Load a BERT model from TensorFlow Hub\n","- Build your own model by combining BERT with a classifier\n","- Train your own model, fine-tuning BERT as part of that\n","- Save your model and use it to classify sentences\n","\n","If you're new to working with the IMDB dataset, please see [Basic text classification](https://www.tensorflow.org/tutorials/keras/text_classification) for more details."]},{"cell_type":"markdown","metadata":{"id":"2PHBpLPuQdmK"},"source":["## About BERT\n","\n","[BERT](https://arxiv.org/abs/1810.04805) and other Transformer encoder architectures have been wildly successful on a variety of tasks in NLP (natural language processing). They compute vector-space representations of natural language that are suitable for use in deep learning models. The BERT family of models uses the Transformer encoder architecture to process each token of input text in the full context of all tokens before and after, hence the name: Bidirectional Encoder Representations from Transformers. \n","\n","BERT models are usually pre-trained on a large corpus of text, then fine-tuned for specific tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"SCjmX4zTCkRK"},"source":["## Setup\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:29:38.728372Z","iopub.status.busy":"2022-03-29T12:29:38.727971Z","iopub.status.idle":"2022-03-29T12:29:40.581474Z","shell.execute_reply":"2022-03-29T12:29:40.580473Z"},"id":"q-YbjCkzw0yU","executionInfo":{"status":"ok","timestamp":1669521266253,"user_tz":480,"elapsed":77048,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1506e251-302e-4c3e-aaec-be7b8228f876"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 497.9 MB 4.3 kB/s \n","\u001b[K     |████████████████████████████████| 462 kB 44.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.4 MB 49.1 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 41.2 MB/s \n","\u001b[?25h"]}],"source":["# A dependency of the preprocessing for BERT inputs\n","!pip install -q -U \"tensorflow-text==2.8.*\""]},{"cell_type":"markdown","metadata":{"id":"5w_XlxN1IsRJ"},"source":["You will use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models)."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:29:40.585969Z","iopub.status.busy":"2022-03-29T12:29:40.585266Z","iopub.status.idle":"2022-03-29T12:29:49.391942Z","shell.execute_reply":"2022-03-29T12:29:49.391141Z"},"id":"b-P1ZOA0FkVJ","executionInfo":{"status":"ok","timestamp":1669521307785,"user_tz":480,"elapsed":41548,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"efcd5db1-f2e8-4946-f865-eff4fb01ad6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 118 kB 16.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 44.6 MB/s \n","\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 43.8 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 45.8 MB/s \n","\u001b[K     |████████████████████████████████| 238 kB 44.7 MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.13.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 43.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 transformers-4.24.0\n"]}],"source":["!pip install -q tf-models-official==2.7.0\n","!pip install tokenizers\n","!pip install transformers"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:29:49.396206Z","iopub.status.busy":"2022-03-29T12:29:49.395613Z","iopub.status.idle":"2022-03-29T12:29:52.068483Z","shell.execute_reply":"2022-03-29T12:29:52.067720Z"},"id":"_XgTpm9ZxoN9","executionInfo":{"status":"ok","timestamp":1669521317958,"user_tz":480,"elapsed":10183,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}}},"outputs":[],"source":["import os\n","import re\n","import json\n","import string\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tokenizers import BertWordPieceTokenizer\n","from transformers import BertTokenizer, TFBertModel, BertConfig\n","from official.nlp import optimization\n","import matplotlib.pyplot as plt\n","\n","tf.get_logger().setLevel('ERROR')\n","\n","max_len = 384\n","configuration = BertConfig() "]},{"cell_type":"markdown","source":["## Setup BERT tokenizer\n"],"metadata":{"id":"qRBBpYNWjlFv"}},{"cell_type":"code","source":["# Save the slow pretrained tokenizer\n","slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","save_path = \"bert_base_uncased/\"\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","slow_tokenizer.save_pretrained(save_path)\n","\n","# Load the fast tokenizer from saved file\n","tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"],"metadata":{"id":"-pAJ6QgNjf6v","executionInfo":{"status":"ok","timestamp":1669521320217,"user_tz":480,"elapsed":2296,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["4a1fa33656bc4d08bd4bd9c4c1d7ac0b","f5ba142a9e8047798c6df21c46de53bf","4d881d2fd316426fbf1f7cce84ecb2e3","585d2ad926384dc9bf39a4e4e534e37c","d24b20bbbdb0416aa6e2237d5d7f6abd","16348c900cea4c08aef61dfada0c0b87","f91e161cfe024b3f9c97e573de60acfc","77a7de7f3fda456c94ba70fc51c0e115","a8c479193ad44942a801eb074006e194","8347c286e2b2475cab733510e7d014e0","7ac4b85336564a8fbab408d413108f0b","f4170930618a41d386b4a56569155ccf","2176db7413b944689230136c9e62030e","0f03942d23fa4809896e7def5b9191cf","ac65e37ba38442bf8a05e7e5b7e6d281","01ccfc9512fa40b9b6d745a35fdba3b1","423a17c9bf534a4fada4c77b4a0b181d","2717373455614460828b197642fee07a","e6c2f89cf0bd45e9a54764806cfa7718","e47bb812a4a14926a2f7a1084fbf8146","b044ca9a00f543c48fd8b4f4ea1ad6cf","a90658084fb14a25b27b11d69d57c2a2","b210b7faba514409aeee7b4c443f4b9e","8d7f5d54a0bb428aba9ba55160177fdc","681cbeb4f8624ddc9cd8308caec7a87a","8ff853ea84fa45a8b59f6333f2991ea0","28d9e9488f2e40e8841cba00f509c021","06ae3581147547629c073d61116dfee7","6d755cf68d71468182b91988df0b073d","134ee8fc79544ccba0a4f0bbb1512262","05c3aee287604367bb039b0d9d6f83dc","dc1e02a44913455b83e42a7f80d6516a","80680f6da18a4d75b75d5fa92225211c"]},"outputId":"031e6a5a-4653-4d30-edd6-07940f401ca6"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1fa33656bc4d08bd4bd9c4c1d7ac0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4170930618a41d386b4a56569155ccf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b210b7faba514409aeee7b4c443f4b9e"}},"metadata":{}}]},{"cell_type":"markdown","source":["Load SQUAD Dataset"],"metadata":{"id":"l9G4DVDhju_u"}},{"cell_type":"code","source":["train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n","train_path = keras.utils.get_file(\"train.json\", train_data_url)\n","eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n","eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"],"metadata":{"id":"TT9c2Ua5jtkO","executionInfo":{"status":"ok","timestamp":1669521321302,"user_tz":480,"elapsed":1093,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ecf0883-fac4-493c-9322-daac38ba66a8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n","30294016/30288272 [==============================] - 0s 0us/step\n","30302208/30288272 [==============================] - 0s 0us/step\n","Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n","4857856/4854279 [==============================] - 0s 0us/step\n","4866048/4854279 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["## Preprocess the SQUAD data"],"metadata":{"id":"lIHLn4kOj5NP"}},{"cell_type":"code","source":["class SquadExample:\n","    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n","        self.question = question\n","        self.context = context\n","        self.start_char_idx = start_char_idx\n","        self.answer_text = answer_text\n","        self.all_answers = all_answers\n","        self.skip = False\n","\n","    def preprocess(self):\n","        context = self.context\n","        question = self.question\n","        answer_text = self.answer_text\n","        start_char_idx = self.start_char_idx\n","\n","        # Clean context, answer and question\n","        context = \" \".join(str(context).split())\n","        question = \" \".join(str(question).split())\n","        answer = \" \".join(str(answer_text).split())\n","\n","        # Find end character index of answer in context\n","        end_char_idx = start_char_idx + len(answer)\n","        if end_char_idx >= len(context):\n","            self.skip = True\n","            return\n","\n","        # Mark the character indexes in context that are in answer\n","        is_char_in_ans = [0] * len(context)\n","        for idx in range(start_char_idx, end_char_idx):\n","            is_char_in_ans[idx] = 1\n","\n","        # Tokenize context\n","        tokenized_context = tokenizer.encode(context)\n","\n","        # Find tokens that were created from answer characters\n","        ans_token_idx = []\n","        for idx, (start, end) in enumerate(tokenized_context.offsets):\n","            if sum(is_char_in_ans[start:end]) > 0:\n","                ans_token_idx.append(idx)\n","\n","        if len(ans_token_idx) == 0:\n","            self.skip = True\n","            return\n","\n","        # Find start and end token index for tokens from answer\n","        start_token_idx = ans_token_idx[0]\n","        end_token_idx = ans_token_idx[-1]\n","\n","        # Tokenize question\n","        tokenized_question = tokenizer.encode(question)\n","\n","        # Create inputs\n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\n","            tokenized_question.ids[1:]\n","        )\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Pad and create attention masks.\n","        # Skip if truncation is needed\n","        padding_length = max_len - len(input_ids)\n","        if padding_length > 0:  # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length)\n","            token_type_ids = token_type_ids + ([0] * padding_length)\n","        elif padding_length < 0:  # skip\n","            self.skip = True\n","            return\n","\n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.start_token_idx = start_token_idx\n","        self.end_token_idx = end_token_idx\n","        self.context_token_to_char = tokenized_context.offsets\n","\n","\n","with open(train_path) as f:\n","    raw_train_data = json.load(f)\n","\n","with open(eval_path) as f:\n","    raw_eval_data = json.load(f)\n","\n","\n","def create_squad_examples(raw_data):\n","    squad_examples = []\n","    for item in raw_data[\"data\"]:\n","        for para in item[\"paragraphs\"]:\n","            context = para[\"context\"]\n","            for qa in para[\"qas\"]:\n","                question = qa[\"question\"]\n","                answer_text = qa[\"answers\"][0][\"text\"]\n","                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n","                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n","                squad_eg = SquadExample(\n","                    question, context, start_char_idx, answer_text, all_answers\n","                )\n","                squad_eg.preprocess()\n","                squad_examples.append(squad_eg)\n","    return squad_examples\n","\n","\n","def create_inputs_targets(squad_examples):\n","    dataset_dict = {\n","        \"input_ids\": [],\n","        \"token_type_ids\": [],\n","        \"attention_mask\": [],\n","        \"start_token_idx\": [],\n","        \"end_token_idx\": [],\n","    }\n","    for item in squad_examples:\n","        if item.skip == False:\n","            for key in dataset_dict:\n","                dataset_dict[key].append(getattr(item, key))\n","    for key in dataset_dict:\n","        dataset_dict[key] = np.array(dataset_dict[key])\n","\n","    x = [\n","        dataset_dict[\"input_ids\"],\n","        dataset_dict[\"token_type_ids\"],\n","        dataset_dict[\"attention_mask\"],\n","    ]\n","    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n","    return x, y\n","\n","\n","train_squad_examples = create_squad_examples(raw_train_data)\n","x_train, y_train = create_inputs_targets(train_squad_examples)\n","print(f\"{len(train_squad_examples)} training points created.\")\n","\n","eval_squad_examples = create_squad_examples(raw_eval_data)\n","x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n","print(f\"{len(eval_squad_examples)} evaluation points created.\")"],"metadata":{"id":"x7GcmFk3j4vY","executionInfo":{"status":"ok","timestamp":1669521409004,"user_tz":480,"elapsed":87708,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f84b93eb-eda2-45fa-d82e-5c62a655a3dc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["87599 training points created.\n","10570 evaluation points created.\n"]}]},{"cell_type":"markdown","source":["## Creating Question-Answering Model using BERT and Functional API\n","\n"],"metadata":{"id":"JgZMYwtKkpOu"}},{"cell_type":"code","source":["def create_model():\n","    ## BERT encoder\n","    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")\n","\n","    ## QA Model\n","    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    embedding = encoder(\n","        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n","    )[0]\n","\n","    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n","    start_logits = layers.Flatten()(start_logits)\n","\n","    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n","    end_logits = layers.Flatten()(end_logits)\n","\n","    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n","    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n","\n","    model = keras.Model(\n","        inputs=[input_ids, token_type_ids, attention_mask],\n","        outputs=[start_probs, end_probs],\n","    )\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n","    optimizer = keras.optimizers.Adam(lr=5e-5)\n","    model.compile(optimizer=optimizer, loss=[loss, loss])\n","    return model"],"metadata":{"id":"wdEVkF9RkorZ","executionInfo":{"status":"ok","timestamp":1669521409005,"user_tz":480,"elapsed":45,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation Functions"],"metadata":{"id":"nGuZRL09laIG"}},{"cell_type":"code","source":["def normalize_text(text):\n","    text = text.lower()\n","\n","    # Remove punctuations\n","    exclude = set(string.punctuation)\n","    text = \"\".join(ch for ch in text if ch not in exclude)\n","\n","    # Remove articles\n","    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","    text = re.sub(regex, \" \", text)\n","\n","    # Remove extra white space\n","    text = \" \".join(text.split())\n","    return text\n","\n","\n","class ExactMatch(keras.callbacks.Callback):\n","    \"\"\"\n","    Each `SquadExample` object contains the character level offsets for each token\n","    in its input paragraph. We use them to get back the span of text corresponding\n","    to the tokens between our predicted start and end tokens.\n","    All the ground-truth answers are also present in each `SquadExample` object.\n","    We calculate the percentage of data points where the span of text obtained\n","    from model predictions matches one of the ground-truth answers.\n","    \"\"\"\n","\n","    def __init__(self, x_eval, y_eval):\n","        self.x_eval = x_eval\n","        self.y_eval = y_eval\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        pred_start, pred_end = self.model.predict(self.x_eval)\n","        count = 0\n","        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n","        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n","            squad_eg = eval_examples_no_skip[idx]\n","            offsets = squad_eg.context_token_to_char\n","            start = np.argmax(start)\n","            end = np.argmax(end)\n","            if start >= len(offsets):\n","                continue\n","            pred_char_start = offsets[start][0]\n","            if end < len(offsets):\n","                pred_char_end = offsets[end][1]\n","                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n","            else:\n","                pred_ans = squad_eg.context[pred_char_start:]\n","\n","            normalized_pred_ans = normalize_text(pred_ans)\n","            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\n","            if normalized_pred_ans in normalized_true_ans:\n","                count += 1\n","        acc = count / len(self.y_eval[0])\n","        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"],"metadata":{"id":"lZ2wLYJxlXXW","executionInfo":{"status":"ok","timestamp":1669521409007,"user_tz":480,"elapsed":45,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = create_model()\n","model.summary()"],"metadata":{"id":"dp6Z-c2rk4oO","executionInfo":{"status":"ok","timestamp":1669521441908,"user_tz":480,"elapsed":32945,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"colab":{"base_uri":"https://localhost:8080/","height":920,"referenced_widgets":["a07b600ee5ff46d2a36830ee69ef2556","a28b7ff9e41e4f289fff39d66058413d","867fc864169e43109a198bc3bbdfa6d4","ec2d46cb94c1491f8874116cbe7d9133","e6c7c4b9b3d34067947c53fe9dc6fa16","542d6550ffac4cc7a5ae3569b834a5a2","4b7c195567704961b973deb56962bbe9","ce62861f87744c1ea4ddf1546b1c9f42","654b137d71fc43e680cc691e557b82b4","8d9923d6cb944b60b21cbd05abcc5997","08696a4cbc6b48b7a8e616c2121aae0a"]},"outputId":"3f9619aa-b4c4-4469-bc75-f28e1150a4f2"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07b600ee5ff46d2a36830ee69ef2556"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 384)]        0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, 384)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 384)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n","                                thPoolingAndCrossAt               'input_3[0][0]',                \n","                                tentions(last_hidde               'input_2[0][0]']                \n","                                n_state=(None, 384,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," start_logit (Dense)            (None, 384, 1)       768         ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," end_logit (Dense)              (None, 384, 1)       768         ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," flatten (Flatten)              (None, 384)          0           ['start_logit[0][0]']            \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 384)          0           ['end_logit[0][0]']              \n","                                                                                                  \n"," activation (Activation)        (None, 384)          0           ['flatten[0][0]']                \n","                                                                                                  \n"," activation_1 (Activation)      (None, 384)          0           ['flatten_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,483,776\n","Trainable params: 109,483,776\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["dataset_name = 'squad'\n","saved_model_path = '/../Code/transfer_learning/'+dataset_name\n","model.save(saved_model_path, include_optimizer=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AvZO-H74L9fI","executionInfo":{"status":"ok","timestamp":1669520802780,"user_tz":480,"elapsed":52835,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"outputId":"2ffcf485-0641-40ed-8a8c-e541b4593f6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["# exact_match_callback = ExactMatch(x_eval, y_eval)\n","# model.fit(\n","#     x_train,\n","#     y_train,\n","#     epochs=1,  # For demonstration, 3 epochs are recommended\n","#     verbose=2,\n","#     batch_size=64,\n","#     callbacks=[exact_match_callback],\n","# )\n"],"metadata":{"id":"NQbO_oOuLSOW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BERT MODEL TRAINED ON SQUAD DATASET!"],"metadata":{"id":"knwiYp8dlqFQ"}},{"cell_type":"markdown","metadata":{"id":"uBthMlTSV8kn"},"source":["### Evaluate the model\n","\n","Let's see how the model performs on SRS Data..."]},{"cell_type":"code","source":["def getTestData():\n","    PATH = os.getcwd()+'/../Data/transfer_learning_dataset'\n","    train_dir = os.path.join(PATH, 'train')\n","    validation_dir = os.path.join(PATH, 'validation')\n","    print(PATH,train_dir, validation_dir)\n","    print(os.listdir(train_dir))\n","    BATCH_SIZE = 1\n","\n","    train_dataset = tf.keras.utils.text_dataset_from_directory(train_dir,batch_size=BATCH_SIZE)\n","    display(train_dataset)\n","\n","# To get test_data\n","# text_data = getTestData()\n","text_data = 'The end user system will initially need to present a user interface where they can select the factory they are working at, the checkpoint they are inspecting at, and the type of car being inspected. This information is stored on the server alongside the defect data that the user inputs later. Second, another menu will allow users to indicate the location, severity, and type of defects. This menu will display a wireframe for the selected model of car, that allows users to place the defect in the appropriate location on the vehicle. Lastly, end users will be able to run three types of reports over previously stored defect data. The first type of report is a QA report, which summarizes vehicle inspections over a specific time range, which is chosen by the user when running the report. It contains all the data stored for the defects over that period, the total number of cars inspected, and the defects per unit. It also contains several tables that show an aggregated car diagram with locations of all recorded defects, and a pie chart that displays the ratios of all defect types over this period. The second report is a Summary of Analysis report, which is a numeric summary of defects over a given period that were entered by a specific analyst. The user running the report is able to specify the date range to run the report on. This report contains the shift the analyst was on, the check point being inspected, and a summary of the number of defects, number of units, and number of defects per unit. The final report type is a weekly chart, which outputs an Excel file containing weekly data over several months. The number of months to run the report on is selected by the user. This report contains weekly statistics for each facility, part name, machine, and data for all defects during that period.'"],"metadata":{"id":"ryPyOUUhp9CA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_raw_result = model(tf.constant(text_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"lGIqu-5MKKvf","executionInfo":{"status":"error","timestamp":1669520403182,"user_tz":480,"elapsed":315,"user":{"displayName":"Sneha Bandi","userId":"00027953615612399574"}},"outputId":"f4eefeb1-7740-4cde-8a04-16ee95bb6f6b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-608a089f9ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_raw_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:37:37.235151Z","iopub.status.busy":"2022-03-29T12:37:37.234581Z","iopub.status.idle":"2022-03-29T12:38:36.128910Z","shell.execute_reply":"2022-03-29T12:38:36.128342Z"},"id":"slqB-urBV9sP"},"outputs":[],"source":["print(tf.sigmoid(bert_raw_result))\n","\n","classifier_model.compile(optimizer=optimizer,\n","                         loss=loss,\n","                         metrics=metrics)\n","\n","history = classifier_model.fit(x=train_ds,\n","                               validation_data=val_ds,\n","                               epochs=epochs)\n","\n","loss, accuracy = classifier_model.evaluate(test_ds)\n","\n","print(f'Loss: {loss}')\n","print(f'Accuracy: {accuracy}')\n","\n","history_dict = history.history\n","print(history_dict.keys())\n","\n","acc = history_dict['binary_accuracy']\n","val_acc = history_dict['val_binary_accuracy']\n","loss = history_dict['loss']\n","val_loss = history_dict['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","fig = plt.figure(figsize=(10, 6))\n","fig.tight_layout()\n","\n","plt.subplot(2, 1, 1)\n","# r is for \"solid red line\"\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","# plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(epochs, acc, 'r', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(loc='lower right')"]},{"cell_type":"markdown","metadata":{"id":"Rtn7jewb6dg4"},"source":["## Export for inference\n","\n","Now you just save your fine-tuned model for later use.\n","\n","Fine tuning\n","In the feature extraction experiment, you were only training a few layers on top of an MobileNetV2 base model. The weights of the pre-trained network were not updated during training.\n","\n","One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n","\n","Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned.\n","Also, you should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning.\n","\n","###  Un-freeze the top layers of the model\n","All you need to do is unfreeze the base_model and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:38:36.428146Z","iopub.status.busy":"2022-03-29T12:38:36.427717Z","iopub.status.idle":"2022-03-29T12:38:42.015407Z","shell.execute_reply":"2022-03-29T12:38:42.014764Z"},"id":"ShcvqJAgVera"},"outputs":[],"source":["classifier_model.trainable = True\n","\n","# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(classifier_model.layers))\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 100\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in classifier_model.layers[:fine_tune_at]:\n","  layer.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"PbI25bS1vD7s"},"source":["## Compile the model\n","As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-29T12:38:42.019271Z","iopub.status.busy":"2022-03-29T12:38:42.018826Z","iopub.status.idle":"2022-03-29T12:38:48.305286Z","shell.execute_reply":"2022-03-29T12:38:48.304688Z"},"id":"gUEWVskZjEF0"},"outputs":[],"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n","              metrics=['accuracy'])\n","\n","model.summary()\n","len(model.trainable_variables)"]},{"cell_type":"code","source":["fine_tune_epochs = 10\n","total_epochs =  initial_epochs + fine_tune_epochs\n","\n","history_fine = model.fit(train_dataset,\n","                         epochs=total_epochs,\n","                         initial_epoch=history.epoch[-1],\n","                         validation_data=validation_dataset)"],"metadata":{"id":"GhOU0U_Er3VF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"528oo5YEr8A_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### After Fine-tuning Evaluating accuracy"],"metadata":{"id":"NBIwZhTIr8qG"}},{"cell_type":"code","source":["acc += history_fine.history['accuracy']\n","val_acc += history_fine.history['val_accuracy']\n","\n","loss += history_fine.history['loss']\n","val_loss += history_fine.history['val_loss']"],"metadata":{"id":"59Zx7Mc_sCRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.ylim([0.8, 1])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","          plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.ylim([0, 1.0])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","         plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"metadata":{"id":"xCSGjccvsEv-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation and prediction\n","Verify the performance of the model on new data using test set."],"metadata":{"id":"nIhBL90NsJim"}},{"cell_type":"code","source":["loss, accuracy = model.evaluate(test_dataset)\n","print('Test accuracy :', accuracy)"],"metadata":{"id":"SgUYikM_sH22"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And now you are all set to use this model to prediction\n","\n"],"metadata":{"id":"yf5ZxXEGsUGJ"}},{"cell_type":"code","source":["#Add Summarization code here"],"metadata":{"id":"SjeIXuNNsXHR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summary\n","Using a pre-trained model for feature extraction: When working with a small dataset, it is a common practice to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training. In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n","\n","Fine-tuning a pre-trained model: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning. In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the original dataset that the pre-trained model was trained on."],"metadata":{"id":"be2xJm6QsbRb"}}],"metadata":{"colab":{"provenance":[{"file_id":"1KYZ-DDC0S7NE5j3gvWp0xQjhyZv4GDHr","timestamp":1669521032795},{"file_id":"1G1Yk0PLT0T8RAU1pk2a77LEc54bhSVZ1","timestamp":1669516324301}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4a1fa33656bc4d08bd4bd9c4c1d7ac0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5ba142a9e8047798c6df21c46de53bf","IPY_MODEL_4d881d2fd316426fbf1f7cce84ecb2e3","IPY_MODEL_585d2ad926384dc9bf39a4e4e534e37c"],"layout":"IPY_MODEL_d24b20bbbdb0416aa6e2237d5d7f6abd"}},"f5ba142a9e8047798c6df21c46de53bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16348c900cea4c08aef61dfada0c0b87","placeholder":"​","style":"IPY_MODEL_f91e161cfe024b3f9c97e573de60acfc","value":"Downloading: 100%"}},"4d881d2fd316426fbf1f7cce84ecb2e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77a7de7f3fda456c94ba70fc51c0e115","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8c479193ad44942a801eb074006e194","value":231508}},"585d2ad926384dc9bf39a4e4e534e37c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8347c286e2b2475cab733510e7d014e0","placeholder":"​","style":"IPY_MODEL_7ac4b85336564a8fbab408d413108f0b","value":" 232k/232k [00:00&lt;00:00, 1.21MB/s]"}},"d24b20bbbdb0416aa6e2237d5d7f6abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16348c900cea4c08aef61dfada0c0b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f91e161cfe024b3f9c97e573de60acfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77a7de7f3fda456c94ba70fc51c0e115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8c479193ad44942a801eb074006e194":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8347c286e2b2475cab733510e7d014e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac4b85336564a8fbab408d413108f0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4170930618a41d386b4a56569155ccf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2176db7413b944689230136c9e62030e","IPY_MODEL_0f03942d23fa4809896e7def5b9191cf","IPY_MODEL_ac65e37ba38442bf8a05e7e5b7e6d281"],"layout":"IPY_MODEL_01ccfc9512fa40b9b6d745a35fdba3b1"}},"2176db7413b944689230136c9e62030e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_423a17c9bf534a4fada4c77b4a0b181d","placeholder":"​","style":"IPY_MODEL_2717373455614460828b197642fee07a","value":"Downloading: 100%"}},"0f03942d23fa4809896e7def5b9191cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6c2f89cf0bd45e9a54764806cfa7718","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e47bb812a4a14926a2f7a1084fbf8146","value":28}},"ac65e37ba38442bf8a05e7e5b7e6d281":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b044ca9a00f543c48fd8b4f4ea1ad6cf","placeholder":"​","style":"IPY_MODEL_a90658084fb14a25b27b11d69d57c2a2","value":" 28.0/28.0 [00:00&lt;00:00, 476B/s]"}},"01ccfc9512fa40b9b6d745a35fdba3b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"423a17c9bf534a4fada4c77b4a0b181d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2717373455614460828b197642fee07a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6c2f89cf0bd45e9a54764806cfa7718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e47bb812a4a14926a2f7a1084fbf8146":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b044ca9a00f543c48fd8b4f4ea1ad6cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a90658084fb14a25b27b11d69d57c2a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b210b7faba514409aeee7b4c443f4b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d7f5d54a0bb428aba9ba55160177fdc","IPY_MODEL_681cbeb4f8624ddc9cd8308caec7a87a","IPY_MODEL_8ff853ea84fa45a8b59f6333f2991ea0"],"layout":"IPY_MODEL_28d9e9488f2e40e8841cba00f509c021"}},"8d7f5d54a0bb428aba9ba55160177fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06ae3581147547629c073d61116dfee7","placeholder":"​","style":"IPY_MODEL_6d755cf68d71468182b91988df0b073d","value":"Downloading: 100%"}},"681cbeb4f8624ddc9cd8308caec7a87a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_134ee8fc79544ccba0a4f0bbb1512262","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05c3aee287604367bb039b0d9d6f83dc","value":570}},"8ff853ea84fa45a8b59f6333f2991ea0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc1e02a44913455b83e42a7f80d6516a","placeholder":"​","style":"IPY_MODEL_80680f6da18a4d75b75d5fa92225211c","value":" 570/570 [00:00&lt;00:00, 13.0kB/s]"}},"28d9e9488f2e40e8841cba00f509c021":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06ae3581147547629c073d61116dfee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d755cf68d71468182b91988df0b073d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"134ee8fc79544ccba0a4f0bbb1512262":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05c3aee287604367bb039b0d9d6f83dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc1e02a44913455b83e42a7f80d6516a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80680f6da18a4d75b75d5fa92225211c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a07b600ee5ff46d2a36830ee69ef2556":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a28b7ff9e41e4f289fff39d66058413d","IPY_MODEL_867fc864169e43109a198bc3bbdfa6d4","IPY_MODEL_ec2d46cb94c1491f8874116cbe7d9133"],"layout":"IPY_MODEL_e6c7c4b9b3d34067947c53fe9dc6fa16"}},"a28b7ff9e41e4f289fff39d66058413d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_542d6550ffac4cc7a5ae3569b834a5a2","placeholder":"​","style":"IPY_MODEL_4b7c195567704961b973deb56962bbe9","value":"Downloading: 100%"}},"867fc864169e43109a198bc3bbdfa6d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce62861f87744c1ea4ddf1546b1c9f42","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_654b137d71fc43e680cc691e557b82b4","value":536063208}},"ec2d46cb94c1491f8874116cbe7d9133":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d9923d6cb944b60b21cbd05abcc5997","placeholder":"​","style":"IPY_MODEL_08696a4cbc6b48b7a8e616c2121aae0a","value":" 536M/536M [00:19&lt;00:00, 19.2MB/s]"}},"e6c7c4b9b3d34067947c53fe9dc6fa16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542d6550ffac4cc7a5ae3569b834a5a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b7c195567704961b973deb56962bbe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce62861f87744c1ea4ddf1546b1c9f42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654b137d71fc43e680cc691e557b82b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d9923d6cb944b60b21cbd05abcc5997":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08696a4cbc6b48b7a8e616c2121aae0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}