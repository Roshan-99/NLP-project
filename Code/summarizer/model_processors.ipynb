{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcVc/XhOJlABC7edHP+KfN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1mx1eXgK0X3K"},"outputs":[],"source":["from summarizer.BertParent import BertParent\n","from typing import List\n","from summarizer.ClusterFeatures import ClusterFeatures\n","from abc import abstractmethod\n","import neuralcoref\n","from spacy.lang.en import English\n","\n","\n","class ModelProcessor(object):\n","\n","    def __init__(self, model='bert-large-uncased',\n","                 vector_size: int = None,\n","                 hidden: int=-2,\n","                 reduce_option: str = 'mean',\n","                 greedyness: float=0.45):\n","        self.model = BertParent(model, vector_size)\n","        self.hidden = hidden\n","        self.vector_size = vector_size\n","        self.reduce_option = reduce_option\n","        self.nlp = English()\n","        self.nlp.add_pipe(self.nlp.create_pipe('sentencizer'))\n","        neuralcoref.add_to_pipe(self.nlp, greedyness=greedyness)\n","\n","    def process_content_sentences(self, body: str, min_length=40, max_length=1000) -> List[str]:\n","        doc = self.nlp(body)._.coref_resolved\n","        doc = self.nlp(doc)\n","        return [c.string.strip() for c in doc.sents\n","                if len(c.string.strip()) > min_length and len(c.string.strip()) < max_length]\n","\n","    # change ratio for four functions below to specify size of summary (keep all ratios consistent); default = 0.2 for all\n","    @abstractmethod\n","    def run_clusters(self, content: List[str], ratio=0.13, algorithm='kmeans', use_first: bool=True) -> List[str]:\n","        raise NotImplementedError(\"Must Implement run_clusters\")\n","\n","    def run(self, body: str, ratio: float=0.13, min_length: int=40, max_length: int=1000,\n","            use_first: bool=True, algorithm='kmeans') -> str:\n","        sentences = self.process_content_sentences(body, min_length, max_length)\n","        res = self.run_clusters(sentences, ratio, algorithm, use_first)\n","        return ' '.join(res)\n","\n","    def __call__(self, body: str, ratio: float=0.13, min_length: int=40, max_length: int=1000,\n","                 use_first: bool=True, algorithm='kmeans') -> str:\n","        return self.run(body, ratio, min_length, max_length)\n","\n","\n","class SingleModel(ModelProcessor):\n","\n","    def __init__(self, model='bert-large-uncased',\n","                 vector_size: int = None,\n","                 hidden: int=-2,\n","                 reduce_option: str = 'mean',\n","                 greedyness: float=0.45):\n","        super(SingleModel, self).__init__(model, vector_size, hidden, reduce_option, greedyness)\n","\n","    def run_clusters(self, content: List[str], ratio=0.13, algorithm='kmeans', use_first: bool= True) -> List[str]:\n","        hidden = self.model(content, self.hidden, self.reduce_option)\n","        hidden_args = ClusterFeatures(hidden, algorithm).cluster(ratio)\n","        if use_first:\n","            if hidden_args[0] != 0:\n","                hidden_args.insert(0,0)\n","        return [content[j] for j in hidden_args]\n","        "]}]}