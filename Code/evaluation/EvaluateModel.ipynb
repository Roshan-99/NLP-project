{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VfUMcQYef7qR",
        "outputId": "753af353-f0ec-49a3-afb5-643605d91567"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install rouge-score\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9SpwpLg3h6L",
        "outputId": "8103ec60-0678-4107-e658-51c033c473aa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "class EvaluateModel(object):\n",
        "\n",
        "    categories = ['goal','description','scope','requirements','architecture','users','summary']\n",
        "    \n",
        "    \n",
        "    \n",
        "    def __init__(self):\n",
        "        print('Evaluating Results...')\n",
        "        self.path = os.getcwd()+'/../Data'\n",
        "        self.categories = ['goal','description','scope','requirements','architecture','users','summary']\n",
        "        self.evalData = self.path + \"/evaluation_data/evaluation_data.csv\"\n",
        "        self.df = None\n",
        "        self.readEvaluation()\n",
        "        self.getBleuScore()\n",
        "        self.scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "        self.getRougeScore()\n",
        "        self.writeResults()\n",
        "    \n",
        "    def tokenize(self, column):\n",
        "        column = column.apply(lambda x: x.split())\n",
        "        return column\n",
        "    \n",
        "    def readEvaluation(self):\n",
        "        self.df = pd.read_csv(self.evalData)\n",
        "        self.df.fillna(\"\", inplace = True)\n",
        "    \n",
        "    def getBleuScore(self):\n",
        "        df = self.df.copy()\n",
        "        df.predicted = self.tokenize(df.predicted)\n",
        "        df.expected = self.tokenize(df.expected)\n",
        "        scores = []\n",
        "        for index, row in df.iterrows():\n",
        "            blue_score = sentence_bleu(list(df.expected), row.predicted)\n",
        "            scores.append(bleu_score)\n",
        "        self.df[\"bleu_score\"] = scores\n",
        "    \n",
        "    def getRougeScore(self):\n",
        "        df = self.df.copy()\n",
        "        rPrec = []\n",
        "        rRec = []\n",
        "        rF = []\n",
        "        \n",
        "        for index, row in df.iterrows():\n",
        "            rouge_score = scorer.score(row.expected, row.predicted)\n",
        "            rPrec.append(rouge_score['rouge1'].precision)\n",
        "            rRec.append(rouge_score['rouge1'].recall)\n",
        "            rF.append(rouge_score['rouge1'].fmeasure)\n",
        "        \n",
        "        self.df[\"rouge_precision\"] = rPrec\n",
        "        self.df[\"rouge_recall\"] = rRec\n",
        "        self.df[\"rouge_fmeasure\"] = rF\n",
        "    \n",
        "    def writeResults(self):\n",
        "        df.to_csv(self.path + \"/evaluation_data/evaluated_data.csv\")\n",
        "    \n",
        "#EvaluateModel()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
